<!DOCTYPE html>
<html lang='en'>

<head>
	<meta charset='UTF-8'>
	<meta name='viewport' content='width=device-width, initial-scale=1, shrink-to-fit=no'>
	<title>Bangzheng Li</title>
	<meta http-equiv='X-UA-Compatible' content='IE=edge'>
	<link rel='stylesheet' href='asset/css/bootstrap.css'>
	<link rel='stylesheet' href='asset/css/all.css'>
	<link rel='stylesheet' href='asset/css/style.css'>
</head>

<body class='bg-light'>
	<header>
		<nav class='navbar navbar-light fixed-top bg-light'>
			<!-- <a class=" nav-name" style="font-family:'Courier New'" ><h4>Bangzheng Li</h4></a> -->
			<a class='navbar-brand col-sm-3 col-md-2 mt-1 ml-5' href='index.html'>
				<!-- <h2>Bangzheng Li</h2> -->
			</a>

			<ul class="nav justify-content-center">
				<li class="nav-item">
					<div style="display: flex;">
						<a class=" nav-link" href="https://scholar.google.com/citations?user=UcegV-cAAAAJ&hl=en">Publications üìÑ</a>
						<a class=" nav-link" href="asset/pdf/Resume_Bangzheng_OCT2025.pdf">CV üìÑ</a>
					</div>
				</li>
				</li>
			</ul>

			<!-- <ul class="nav justify-content-center">
				<li class="nav-item">
				</li>
				</li>
			</ul> -->
		</nav>
	</header>
	<section id="top">
		<div class='container pt-5'>
			<div class="row pt-5">
				<div class="col-4">
					<img class="img-fluid rounded" src="asset/image/me.png" alt="headshot">
					<!-- <img class="img-fluid rounded" src="asset/image/me2.jpeg" alt="headshot"> -->
				</div>
				<div class="col-6">
					<h3 class=''> <span style="font-family:'verdana'">Bangzheng Li</span> 
					</h3>
					<div class="row">
						<p class="text-muted mx-3 my-2">Email: bzhli[at]ucdavis[dot]edu</p>
						<span class="icon"><a class="text-dark"
								href="https://scholar.google.com/citations?user=UcegV-cAAAAJ&hl=en"><i
									class="fas fa-graduation-cap mx-2"></i></a></span>
					</div>
					<p>
						üëã Hi, I am Bangzheng Li, a final-year PhD candidate in Computer Science at UC Davis (previously at Uniersity of Southern California). I'm a member of LUKA Lab where I am very grateful to be advised by Dr. <a class="" href="https://muhaochen.github.io/">Muhao Chen</a> and funded by Provost's Fellowship. 
					</p>
					<p>
						My research focuses on Multimodal Large Language Models (MLLMs), with a particular emphasis on understanding and reasoning across text and vision. I am especially interested in the emergence of unified reasoning‚Äîwhere information flows seamlessly across all modalities.
					</p>
					<p>
						I believe in a hyper manifold that accomodates all the modalities
					</p>
					<p>
						I believe in Reinforcement Learning.
					</p>
					

					<p>
						I received my Bachelor's Degree from University of Illinois at Urbana-Champaign where I was fortunate to work with Dr. <a class="" href="https://hanj.cs.illinois.edu/">Jiawei Han</a> on various text classification and document classification tasks.
					</p>

					<style>
						.badge {
						  display: inline-block;
						  padding: 0.25rem 0.5rem;
						  border-radius: 999px;
						  background: #0ea5a4; /* teal */
						  color: white;
						  font-weight: 600;
						  font-size: 0.875rem;
						  margin-left: 0.5rem;
						}
					  </style>
					  
					  <p>
						<strong>I am graduating in Summer 2026 and am actively seeking full-time oppotunities.</strong>
						<span class="badge" aria-label="Open to work">Open to work</span>
					  </p>
				</div>
			</div>
		</div>
	</section>

	<section class="mx-5 my-5" id="experience">
		<h3 class="mx-5">üíº Work Experience</h3>
		<ul class="mx-5 list-disc list-inside space-y-3">
		  <li class="bg-light p-3 rounded-lg shadow-sm">
			<strong>Fall 2025</strong> ‚Äî Student Researcher @ 
			<a href="https://deepmind.google" target="_blank" rel="noopener noreferrer">Google</a>, Mountain View, CA
			<ul class="list-disc list-inside ml-6 text-gray-700">
			  <li>Advisor: <a href="https://www.chenqu.me/" target="_blank" rel="noopener noreferrer"><strong>Chen Qu</strong></a>,
				<a href="https://nijianmo.github.io/" target="_blank" rel="noopener noreferrer"><strong>Jianmo Ni</strong></a></li>
			</ul>
		  </li>
	  
		  <li class="bg-light p-3 rounded-lg shadow-sm">
			<strong>Summer 2025</strong> ‚Äî Research Intern @ 
			<a href="https://www.amd.com/en/developer/resources/open-source-models.html" target="_blank" rel="noopener noreferrer">AMD GenAI</a>, Santa Clara, CA
			<ul class="list-disc list-inside ml-6 text-gray-700">
			  <li>Advisor: <a href="https://sunxm2357.github.io" target="_blank" rel="noopener noreferrer"><strong>Ximeng Sun</strong></a>,
							<a href="https://zicliu.wixsite.com/mysite" target="_blank" rel="noopener noreferrer"><strong>Zicheng Liu</strong></a>
				</li>
			</ul>
		  </li>
		</ul>
	  </section>
	  

	<section class="mx-5 my-5" id="research">
		<h3 class="mx-5">üìë Selected Research Projects</h3>
		<br>
		<ul class="list-group list-group-flush mx-5">

			<li class="list-group-item bg-light">
				<div class="row">
					<div class="col-4"><img class="img-fluid" src="asset/image/lvr_main.svg" alt="blink">
					</div>
					<div class="col-7">
						<h5 id='top' class=''>Latent Visual Reasoning</h5>
						<p><u>Bangzheng Li</u>, Ximeng Sun , Jiang Liu, Ze Wang, Jialian Wu, Xiaodong Yu, Hao Chen, Emad Barsoum, Muhao Chen, Zicheng Liu</p>
						<p>preprint, 2025</p>
						<p>
							<a href="https://arxiv.org/pdf/2509.24251">[paper]</a>
							<a href="http://www.libangzheng.com/lvr-project-page/">[website]</a>
							<a href="https://github.com/VincentLeebang/lvr">[code]</a>
							<a href="https://huggingface.co/vincentleebang/LVR-7B">[<img src="asset/image/hf-logo.png" width="25" /> model: LVR-7B]</a>
						</p>
				</div>
			</li>
			<br>

			<li class="list-group-item bg-light">
				<div class="row">
					<div class="col-4"><img class="img-fluid" src="asset/image/qlip.png" alt="blink">
					</div>
					<div class="col-7">
						<h5 id='top' class=''>QLIP: A Dynamic Quadtree Vision Prior Enhances
							MLLM Performance Without Retraining</h5>
						<p>Kyle R. Chickering, <u>Bangzheng Li</u>, Muhao Chen </p>
						<p>preprint, 2025</p>
						<p>
							<a href="https://arxiv.org/pdf/2505.23004">[paper]</a>
						</p>
				</div>
			</li>
			<br>

			<li class="list-group-item bg-light">
				<div class="row">
					<div class="col-4"><img class="img-fluid" src="asset/image/blink.png" alt="blink">
					</div>
					<div class="col-7">
						<h5 id='top' class=''>BLINK: Multimodal Large Language Models Can See but Not Perceive</h5>
						<p>Xingyu Fu*, Yushi Hu*, <u>Bangzheng Li</u>, Yu Feng, Haoyu Wang, Xudong Lin, Dan Roth, Noah A. Smith, Wei-Chiu Ma‚Ä†, Ranjay Krishna‚Ä†</p>
						<p>ECCV 2024, <span style="color:red"><b>Spotlight</b></span> of cVinW@CVPR 2024, <span style="color:blue"><b>36K</b></span> total downloads.</p>
						<p>
							<a href="https://arxiv.org/abs/2404.12390">[paper]</a>
							<a href="https://zeyofu.github.io/blink/">[website]</a>
							<a href="https://github.com/zeyofu/BLINK_Benchmark">[code]</a>
							<a href="https://huggingface.co/datasets/BLINK-Benchmark/BLINK">[dataset]</a>
							<a href="https://eval.ai/web/challenges/challenge-page/2287/overview">[eval]</a>
							<a href="https://twitter.com/XingyuFu2/status/1781368539213082683">[twitter]</a>
							<a href="https://huggingface.co/papers/2404.12390">[<img src="asset/image/hf-logo.png" width="25" /> Paper of the day]</a>
						</p>
				</div>
			</li>
			<br>

			<li class="list-group-item bg-light">
				<div class="row">
					<div class="col-4"><img class="img-fluid" src="asset/image/semclip.png" alt="blink">
					</div>
					<div class="col-7">
						<h5 id='top' class=''>Semantic-Clipping: Efficient Vision-Language Modeling with Semantic-Guidedd Visual Selection</h5>
						<p><u>Bangzheng Li</u>, Fei Wang, Ben Zhou, Nan Xu, Sheng Zhang, Hoifung Poon, Muhao Chen</p>
						<p>preprint, 2024</p>
						<p>
							<a href="https://arxiv.org/pdf/2503.11794?">[paper]</a>
						</p>
				</div>
			</li>
			<br>

			<li class="list-group-item bg-light">
				<div class="row">
					<div class="col-4"><img class="img-fluid" src="asset/image/deceptive.png" alt="deceptive">
					</div>
					<div class="col-7">
						<h5 id='top' class=''>Deceptive Semantic Shortcuts on Reasoning Chains: How Far Can Models Go without Hallucination?</h5>
						<p><u>Bangzheng Li</u>, Ben Zhou, Fei Wang, Xingyu Fu, Dan Roth, Muhao Chen</p>
						<p>NAACL. 2024.</p>
						<p>
							<a href="https://arxiv.org/paper/2311.09702">[paper]</a>
							<a href="https://vincentleebang.github.io/eureqa.github.io/">[website]</a>
							<a href="https://github.com/VincentLeebang/eureqa">[code]</a>
							<a href="https://huggingface.co/datasets/vincentleebang/EUREQA">[dataset]</a>
						</p>
				</div>
			</li>
			<br>

			<li class="list-group-item bg-light">
				<div class="row">
					<div class="col-4"><img class="img-fluid" src="asset/image/lite.png" alt="lite">
					</div>
					<div class="col-7">
						<h5 id='top' class=''>Ultra-fine Entity Typing with Indirect Supervision from Natural Language Inference</h5>
						<p><u>Bangzheng Li</u>,Wenpeng Yin, Muhao Chen</p>
						<p>TACL. 2022.</p>
						<p>
							<a href="https://arxiv.org/abs/2202.06167">[paper]</a>	
							<a href="https://github.com/luka-group/lite">[code]</a>
						</p>				
				</div>
			</li>
			<br>

			<li class="list-group-item bg-light">
				<div class="row">
					<div class="col-4"><img class="img-fluid" src="asset/image/famicon.png" alt="famicon">
					</div>
					<div class="col-7">
						<h5 id='top' class=''>FAMICOM: Further Demystifying Prompts for Language Models with Task-Agnostic Performance Estimation</h5>
						<p><u>Bangzheng Li</u>, Bangzheng Li, Ben Zhou, Xingyu Fu, Fei Wang, Dan Roth, Muhao Chen</p>
						<p>Arxiv 2024 June</p>
						<p>
							<a href="https://arxiv.org/abs/2406.11243">[paper]</a>
							<!-- <a href="https://famicon.github.io/">[website]</a>
							<a href="https://github.com/famicon/famicon">[code]</a>
							<a href="https://huggingface.co/datasets/famicon/famicon">[dataset]</a>
							<a href="https://x.com/fwang_nlp/status/1805979479791280247">[twitter]</a> -->
						</p>
				</div>
			</li>
			<br>

			<li class="list-group-item bg-light">
				<div class="row">
					<div class="col-4"><img class="img-fluid" src="asset/image/affgen.png" alt="affgen">
					</div>
					<div class="col-7">
						<h5 id='top' class=''>Affective and Dynamic Beam Search for Story Generation</h5>
						<p>Tenghao Huang, Ehsan Qasemi, <u>Bangzheng Li</u>, He Wang, Faeze Brahman, Muhao Chen, Snigdha Chaturvedi</p>
						<p>EMNLP. 2023.</p>
						<p>
							<a href="https://arxiv.org/abs/2310.15079">[paper]</a>
							<a href="https://github.com/tenghaohuang/AFFGEN">[code]</a>
						</p>
				</div>
			</li>
			<br>
			<br>

			<li class="list-group-item bg-light">
				<div class="row">
					<div class="col-4"><img class="img-fluid" src="asset/image/unist.png" alt="unist">
					</div>
					<div class="col-7">
						<h5 id='top' class=''>Unified semantic typing with meaningful label inference</h5>
						<p>James Y. Huang, <u>Bangzheng Li</u>, Jiashu Xu, Muhao Chen</p>
						<p>NAACL. 2022.</p>
						<p>
							<a href="https://aclanthology.org/2022.naacl-main.190.pdf">[paper]</a>
							<!-- <a href="https://tiger-ai-lab.github.io/ImagenHub/">[website]</a> -->
							<a href="https://github.com/luka-group/UniST">[code]</a>
							<!-- <a href="https://huggingface.co/ImagenHub">[dataset]</a> -->
						</p>
				</div>
			</li>
			<br>

			<li class="list-group-item bg-light">
				<div class="row">
					<div class="col-4"><img class="img-fluid" src="asset/image/diagnoseet.png" alt="diagnoseet">
					</div>
					<div class="col-7">
						<h5 id='top' class=''>Does Your Model Classify Entities Reasonably? Diagnosing and Mitigating Spurious Correlations in Entity Typing</h5>
						<p>Nan Xu, Fei Wang, <u>Bangzheng Li</u>, Mingtao Dong, Muhao Chen</p>
						<p>EMNLP. 2022.</p>
						<p>
							<a href="https://arxiv.org/abs/2205.12640">[paper]</a>
							<!-- <a href="https://tiger-ai-lab.github.io/ImagenHub/">[website]</a> -->
						</p>
				</div>
			</li>
			<br>

			<li class="list-group-item bg-light">
				<div class="row">
					<div class="col-4"><img class="img-fluid" src="asset/image/covid-kg.png" alt="covid-kg">
					</div>
					<div class="col-7">
						<h5 id='top' class=''>COVID-19 Literature Knowledge Graph Construction and Drug Repurposing Report Generation</h5>
						<p>Qingyun Wang, Manling Li, Xuan Wang, Nikolaus Parulian, Guangxing Han, Jiawei Ma, Jingxuan Tu, Ying Lin, Ranran Haoran Zhang, Weili Liu, Aabhas Chauhan, Yingjun Guan, <u>Bangzheng Li</u>, Ruisong Li, Xiangchen Song, Yi Fung, Heng Ji, Jiawei Han, Shih-Fu Chang, James Pustejovsky, Jasmine Rah, David Liem, Ahmed ELsayed, Martha Palmer, Clare Voss, Cynthia Schneider, Boyan Onyshkevych

						</p>
						<p>NAACL. 2021, <span style="color:red"><b>Best Demo Paper</b></span></p>
						<p>
							<a href="https://aclanthology.org/2021.naacl-demos.8/">[paper]</a>
							<a href="https://blender.cs.illinois.edu/covid19/">[website]</a>
							<!-- <a href="https://github.com/zeyofu/EDL">[code]</a> -->
							<!-- <a href="https://huggingface.co/ImagenHub">[dataset]</a> -->
						</p>
				</div>
			</li>
			<br>


			<li class="list-group-item bg-light">
				<div class="row">
					<div class="col-4"><img class="img-fluid" src="asset/image/doc2graph.png" alt="doc2graph">
					</div>
					<div class="col-7">
						<h5 id='top' class=''>Neural Concept Map Generation for Effective Document Classification with Interpretable Structured Summarization</h5>
						<p>Carl Yang, Jieyu Zhang, Haonan Wang, <u>Bangzheng Li</u>, Jiawei Han</p>
						<p>SIGIR. 2020.</p>
						<p>
							<a href="https://hanj.cs.illinois.edu/pdf/sigir20_cyang.pdf">[paper]</a>
							<!-- <a href="https://tiger-ai-lab.github.io/ImagenHub/">[website]</a> -->
							<!-- <a href="https://github.com/zeyofu/EDL">[code]</a> -->
						</p>
				</div>
			</li>

			<li class="list-group-item bg-light">
				<div class="row">
					<div class="col-4"><img class="img-fluid" src="asset/image/covidner.png" alt="covidner">
					</div>
					<div class="col-7">
						<h5 id='top' class=''>Comprehensive Named Entity Recognition on CORD-19 with Distant or Weak Supervision</h5>
						<p>Xuan Wang, Xiangchen Song, <u>Bangzheng Li</u>, Yingjun Guan, Jiawei Han</p>
						<p>ISMB. 2020.</p>
						<p>
							<a href="https://arxiv.org/abs/2003.12218">[paper]</a>
							<!-- <a href="https://tiger-ai-lab.github.io/ImagenHub/">[website]</a> -->
							<!-- <a href="https://github.com/zeyofu/EDL">[code]</a> -->
						</p>
				</div>
			</li>

			<li class="list-group-item bg-light">
				<div class="row">
					<div class="col-4"><img class="img-fluid" src="asset/image/covidner2.jpeg" alt="covidner2">
					</div>
					<div class="col-7">
						<h5 id='top' class=''>Fine-Grained Named Entity Recognized Dataset of COVID-19 Literature</h5>
						<p>Xuan Wang, Xiangchen Song, <u>Bangzheng Li</u>, Kang Zhou, Qi Li, Jiawei Han</p>
						<p>BIBM. 2020.</p>
						<p>
							<a href="https://hanj.cs.illinois.edu/pdf/bibm20_xwang.pdf">[paper]</a>
							<!-- <a href="https://tiger-ai-lab.github.io/ImagenHub/">[website]</a> -->
							<!-- <a href="https://github.com/zeyofu/EDL">[code]</a> -->
						</p>
				</div>
			</li>
			<br>
		</ul>
		</div>
	</section>




	

	<!-- <section class="mx-5 my-5" id="golf">
		<h3 class="mx-5">‚õ≥Ô∏èüèåÔ∏è Selections</h3>
		<div class="row mx-5">
			<div class="col-6">
				<div class="ratio ratio-16x9">
					<iframe class="home-vid" src="https://www.youtube.com/embed/MvXeK9cwEVs" title="YouTube video"
						allowfullscreen></iframe>
				</div>
			</div>
			<div class="col-6">
				<div class="ratio ratio-16x9">
					<iframe class="home-vid" src="https://www.youtube.com/embed/2AwFT3Q2caM" title="YouTube video"
						allowfullscreen></iframe>
				</div>
			</div>
		</div>
		<p class="mx-5 d-flex justify-content-end"><a class='' href='pages/dance.html' role='button'>Watch
				more &raquo;</a></p>
		</div>
	</section> -->
	<hr class='featurette-divider'>
	<footer>
		<p class='mx-5 d-flex justify-content-end'><a class="" href='#top'>Back to top</a></p>
	</footer>
</body>

</html>
